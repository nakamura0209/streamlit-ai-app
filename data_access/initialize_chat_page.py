# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’åˆæœŸåŒ–ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã™ã‚‹é–¢æ•°
from logging import Logger
import os
from typing import Any, Dict, List, Tuple, Union
import openai

import streamlit as st
from data_source.langchain.lang_chain_chat_model_factory import ModelParameters
from data_source.openai_data_source import MODELS, Role
from logs.app_logger import set_logging
from logs.log_decorator import log_decorator


logger: Logger = set_logging("lower.sub")


@log_decorator(logger)
def draw_sidebar_divider():
    st.sidebar.markdown("---")


# ä¼šè©±å±¥æ­´ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ä¿å­˜ã™ã‚‹é–¢æ•°
@log_decorator(logger)
def save_conversation_to_markdown(filename: str, messages: List[Dict[str, str]]) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸä¼šè©±å±¥æ­´ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™ã€‚

    Parameters:
    filename (str): ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã€‚".md" ã§çµ‚ã‚ã£ã¦ã„ãªã„å ´åˆã¯ã€æ‹¡å¼µå­ãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚
    messages (List[Dict[str, str]]): ä¼šè©±ã®å„ãƒ¡ãƒƒãƒ¼ã‚¸ã‚’å«ã‚€è¾æ›¸ã®ãƒªã‚¹ãƒˆã€‚

    Returns:
    str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã€‚

    Raises:
    IOError: ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã«ç™ºç”Ÿã—ã¾ã™ã€‚
    """
    markdown_filename = f"{filename}.md" if not filename.endswith(".md") else filename

    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
    markdown_text = ""
    for message in messages:
        role = message.get("role")
        content = message.get("content", "")
        prefix = f"**{role.title()}:** " if role in (Role.USER.value, Role.ASSISTANT.value) else ""
        markdown_text += f"{prefix}{content}\n\n"

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    with open(markdown_filename, "w", encoding="utf-8") as file:
        file.write(markdown_text)

    return markdown_filename


# Streamlitã‚’ä½¿ç”¨ã—ã¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹é–¢æ•°
@log_decorator(logger)
def add_download_button_to_sidebar(messages: List[Dict[str, str]]):
    """
    ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã¨ãƒ•ã‚¡ã‚¤ãƒ«åå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¿½åŠ ã™ã‚‹ã€‚

    ã“ã®é–¢æ•°ã¯Streamlitã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¼šè©±å±¥æ­´ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã€'Generate History Log'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€
    ä¼šè©±ãŒMarkdownãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã•ã‚Œã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã€‚

    Parameters:
    - messages (List[Dict[str, str]]): ä¼šè©±ã®å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è©³ç´°ã‚’å«ã‚€è¾æ›¸ã®ãƒªã‚¹ãƒˆã€‚
    """
    with st.sidebar:
        st.write("## Download Conversation")
        default_filename = "conversation"
        filename = st.text_input("Enter filename for download:", value=default_filename)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ'Generate History Log'ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸå ´åˆã®å‡¦ç†
        if st.button("Generate History Log"):
            # ä¼šè©±ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªï¼ˆåˆæœŸåŒ–æ™‚ã®ç©ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é™¤ãï¼‰
            if len(messages) > 1:
                # ä¼šè©±ã‚’Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                markdown_filename = save_conversation_to_markdown(filename, messages)
                with open(markdown_filename, "rb") as file:
                    st.download_button(
                        label="Download",
                        data=file,
                        file_name=markdown_filename,
                        mime="text/markdown",
                    )
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                os.remove(markdown_filename)
            else:
                st.warning("No conversation to download.")


# ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•°
@log_decorator(logger)
def clear_conversations() -> None:
    """
    ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
    """
    # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¨­å®š
    clear_button = st.sidebar.button("Clear", key="clear")
    if clear_button:
        st.info("Conversation history has been deleted.")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.costs = []
        st.session_state.prompt_tokens = []
        st.session_state.completion_tokens = []


@log_decorator(logger)
# ä¼šè©±ã®ã‚³ã‚¹ãƒˆã‚’è¡¨ç¤ºã™ã‚‹
def display_total_costs() -> None:
    """
    ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ä¼šè©±ã®ç·ã‚³ã‚¹ãƒˆã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°ã€‚

    ã“ã®é–¢æ•°ã¯ã€Streamlitã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã€ŒShow Total Costsã€ãƒœã‚¿ãƒ³ã‚’è¿½åŠ ã—ã€
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã“ã®ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹
    ç·ã‚³ã‚¹ãƒˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ã‚³ã‚¹ãƒˆãŒæœªå®šç¾©ã®å ´åˆã¯ã€0å††ã¨ã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚

    Returns:
        None
    """
    st.sidebar.markdown("## Costs")
    show_cost_button = st.sidebar.button("Show Total Costs")
    if show_cost_button:
        logger.debug(f"st.session_state.costs = {st.session_state.costs}")
        if st.session_state.costs:
            st.sidebar.markdown(f"**{st.session_state.costs} YEN**")
            st.sidebar.markdown(f"**Prompt Tokens: {st.session_state.prompt_tokens}**")
            st.sidebar.markdown(f"**Completion Tokens: {st.session_state.completion_tokens}**")
        else:
            st.sidebar.markdown(f"**0 YEN**")


# ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã™ã‚‹é–¢æ•°
@log_decorator(logger)
def select_model(
    model_key: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    frequency_penalty: float,
    presence_penalty: float,
) -> ModelParameters:
    """
    è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã€ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¾ã™ã€‚

    Args:
        model_key (str): é¸æŠã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ¼ã€‚
        temperature (float): ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ãŸã‚ã®temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚

    Returns:
        ModelParameters: é¸æŠã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚
    """
    model_config: Dict[str, Any] = MODELS[model_key]["config"]

    # OpenAI APIã®è¨­å®šã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
    st.session_state["openai_model"] = model_config["model_version"]
    openai.api_type, openai.api_base, openai.api_version, openai.api_key = (
        model_config["api_type"],
        model_config["base_url"],
        model_config["api_version"],
        model_config["api_key"],
    )

    # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
    language_model_parameters = ModelParameters(
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=top_p,
        frequency_penalty=frequency_penalty,
        presence_penalty=presence_penalty,
        deployment_name=model_config["deployment_name"],
    )

    st.info(f"{model_key} is selected")

    return language_model_parameters


@log_decorator(logger)
def initialize_page_base() -> None:
    """åŸºæœ¬çš„ãªãƒšãƒ¼ã‚¸æ§‹é€ ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    st.set_page_config(page_title="Stream-AI-Chat", page_icon="ğŸ¤–")
    st.header("Stream-AI-Chat")
    st.sidebar.title("Options")


@log_decorator(logger)
def initialize_sidebar() -> Tuple[Union[str, Any], int, float, float, float, float]:
    """
    ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã—ã€ãã®å€¤ã‚’è¿”ã—ã¾ã™ã€‚

    é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«é–¢é€£ã™ã‚‹æ§˜ã€…ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãŸã‚ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’Streamlitã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ä½œæˆã—ã¾ã™ã€‚
    ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ¶é™ã‚’å–å¾—ã—ã€ãã‚Œã«å¿œã˜ã¦ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¨­å®šã—ã¾ã™ã€‚

    Args:

    Returns:
    - Tuple[int, float, float, float, float]: max_tokens, temperature, top_p, frequency_penalty,
      presence_penaltyã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®å€¤ã‚’å«ã‚€ã‚¿ãƒ—ãƒ«ã€‚
    """
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    st.sidebar.header("Model Selection")  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ˜ãƒƒãƒ€ãƒ¼
    # ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
    model_key: str = st.sidebar.radio("Select a model:", list(MODELS.keys()))  # type: ignore
    logger.info(f"User has switched to model {model_key}")
    # ä¼šè©±å±¥æ­´å‰Šé™¤ãƒœã‚¿ãƒ³ã®è¿½åŠ 
    clear_conversations()
    draw_sidebar_divider()  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®åŒºåˆ‡ã‚Šç·š

    # ä¼šè©±å±¥æ­´ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®è¿½åŠ 
    add_download_button_to_sidebar(st.session_state.messages)
    draw_sidebar_divider()

    # ã‚³ã‚¹ãƒˆè¡¨ç¤ºãƒœã‚¿ãƒ³ã®è¿½åŠ 
    display_total_costs()
    draw_sidebar_divider()  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®åŒºåˆ‡ã‚Šç·š

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.sidebar.header("Model Parameters")
    model_parameter = MODELS[model_key]["parameter"]

    max_tokens = st.sidebar.slider(
        "max_tokens: ",  # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        min_value=1,
        max_value=model_parameter["max_tokens"],
        value=2048,
        step=1,
    )
    temperature = st.sidebar.slider(
        "temperature: ",  # æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        min_value=0.0,
        max_value=model_parameter["max_temperature"],
        value=0.0,
        step=0.1,
    )
    top_p = st.sidebar.slider(
        "top_p: ",  # ãƒˆãƒƒãƒ—Pã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        min_value=0.0,
        max_value=model_parameter["max_top_p"],
        value=0.0,
        step=0.1,
    )
    frequency_penalty = st.sidebar.slider(
        "frequency_penalty: ",  # é »åº¦ãƒšãƒŠãƒ«ãƒ†ã‚£
        min_value=0.0,
        max_value=model_parameter["max_frequency_penalty"],
        value=0.0,
        step=0.1,
    )
    presence_penalty = st.sidebar.slider(
        "presence_penalty: ",  # å­˜åœ¨ãƒšãƒŠãƒ«ãƒ†ã‚£
        min_value=0.0,
        max_value=model_parameter["max_presence_penalty"],
        value=0.0,
        step=0.1,
    )

    return model_key, max_tokens, temperature, top_p, frequency_penalty, presence_penalty
