# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’åˆæœŸåŒ–ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã™ã‚‹é–¢æ•°
from logging import Logger
from typing import Any, Dict, Tuple, Union
import openai

import streamlit as st
from data_source.langchain.lang_chain_chat_model_factory import ModelParameters
from data_source.openai_data_source import MODELS
from logs.app_logger import set_logging
from logs.log_decorator import log_decorator


logger: Logger = set_logging("lower.sub")


@log_decorator(logger)
def initialize_page_base() -> None:
    """åŸºæœ¬çš„ãªãƒšãƒ¼ã‚¸æ§‹é€ ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    st.set_page_config(page_title="Stream-AI-Chat", page_icon="ğŸ¤–")
    st.header("Stream-AI-Chat")
    st.sidebar.title("Options")


@log_decorator(logger)
def initialize_sidebar() -> Tuple[Union[str, Any], int, float, float, float, float]:
    """
    ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã—ã€ãã®å€¤ã‚’è¿”ã—ã¾ã™ã€‚

    é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«é–¢é€£ã™ã‚‹æ§˜ã€…ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãŸã‚ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’Streamlitã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ä½œæˆã—ã¾ã™ã€‚
    ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆ¶é™ã‚’å–å¾—ã—ã€ãã‚Œã«å¿œã˜ã¦ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¨­å®šã—ã¾ã™ã€‚

    Args:

    Returns:
    - Tuple[int, float, float, float, float]: max_tokens, temperature, top_p, frequency_penalty,
      presence_penaltyã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®å€¤ã‚’å«ã‚€ã‚¿ãƒ—ãƒ«ã€‚
    """
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: ãƒ¢ãƒ‡ãƒ«é¸æŠã¨ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    st.sidebar.header("Model Selection")  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ˜ãƒƒãƒ€ãƒ¼
    # ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
    model_key: Union[str, Any] = st.sidebar.radio("Select a model:", list(MODELS.keys()))
    # ä¼šè©±å±¥æ­´å‰Šé™¤ãƒœã‚¿ãƒ³ã®è¿½åŠ 
    initialize_message_state()
    st.sidebar.markdown("---")  # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®åŒºåˆ‡ã‚Šç·š

    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    st.sidebar.header("Model Parameters")
    model_parameter = MODELS[model_key]["parameter"]

    max_tokens = st.sidebar.slider(
        "max_tokens: ",  # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        min_value=1,
        max_value=model_parameter["max_tokens"],
        value=2048,
        step=1,
    )
    temperature = st.sidebar.slider(
        "temperature: ",  # æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        min_value=0.0,
        max_value=model_parameter["max_temperature"],
        value=0.0,
        step=0.1,
    )
    top_p = st.sidebar.slider(
        "top_p: ",  # ãƒˆãƒƒãƒ—Pã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        min_value=0.0,
        max_value=model_parameter["max_top_p"],
        value=0.0,
        step=0.1,
    )
    frequency_penalty = st.sidebar.slider(
        "frequency_penalty: ",  # é »åº¦ãƒšãƒŠãƒ«ãƒ†ã‚£
        min_value=0.0,
        max_value=model_parameter["max_frequency_penalty"],
        value=0.0,
        step=0.1,
    )
    presence_penalty = st.sidebar.slider(
        "presence_penalty: ",  # å­˜åœ¨ãƒšãƒŠãƒ«ãƒ†ã‚£
        min_value=0.0,
        max_value=model_parameter["max_presence_penalty"],
        value=0.0,
        step=0.1,
    )

    return model_key, max_tokens, temperature, top_p, frequency_penalty, presence_penalty


# ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã™ã‚‹é–¢æ•°
@log_decorator(logger)
def select_model(
    model_key: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    frequency_penalty: float,
    presence_penalty: float,
) -> ModelParameters:
    """
    è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã€ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¾ã™ã€‚

    Args:
        model_key (str): é¸æŠã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ¼ã€‚
        temperature (float): ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ãŸã‚ã®temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚

    Returns:
        ModelParameters: é¸æŠã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚
    """
    model_config: Dict[str, Any] = MODELS[model_key]["config"]

    # OpenAI APIã®è¨­å®šã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
    st.session_state["openai_model"] = model_config["model_version"]
    openai.api_type, openai.api_base, openai.api_version, openai.api_key = (
        model_config["api_type"],
        model_config["base_url"],
        model_config["api_version"],
        model_config["api_key"],
    )

    # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
    llm = ModelParameters(
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=top_p,
        frequency_penalty=frequency_penalty,
        presence_penalty=presence_penalty,
        deployment_name=model_config["deployment_name"],
    )

    st.info(f"{model_key} is selected")

    return llm


# ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•°
@log_decorator(logger)
def initialize_message_state() -> None:
    """
    ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
    """
    # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¨­å®š
    clear_button = st.sidebar.button("Clear", key="clear")
    if clear_button:
        st.info("Conversation history has been deleted.")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.costs = []
