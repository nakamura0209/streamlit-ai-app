import os
from urllib import response
import openai
import streamlit as st
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage


class LangchainChatModelFactory:
    @staticmethod
    def create_instance():
        return AzureChatOpenAI(
            openai_api_base="https://openai-test-gpt4-20231118.openai.azure.com/",  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
            openai_api_version="2023-07-01-preview",  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
            deployment_name="openai-test-gpt4",  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
            openai_api_key="547aae27000d4df79923b93736993d8a",  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
            openai_api_type="azure",
            model_version="gpt-4",
            # tiktoken_model_name=os.environ.get("AZURE_OPENAI_TIKTOKEN_MODEL_NAME", ""),
            temperature=0,
        )


def main():
    st.set_page_config(page_title="Stream-AI-Chat", page_icon="ğŸ¤–")
    st.header("Stream-AI-Chat")

    llm = LangchainChatModelFactory.create_instance()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = [SystemMessage(content="")]

    # ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("Input Your Message..."):
        st.session_state.messages.append(HumanMessage(content=user_input))  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
        with st.spinner("Generating ChatGPT answers..."):
            response = llm(st.session_state.messages)  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
        st.session_state.messages.append(AIMessage(content=response.content))  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚

    messages = st.session_state.get("messages", [])
    for message in messages:
        st.write(message)


if __name__ == "__main__":
    main()
