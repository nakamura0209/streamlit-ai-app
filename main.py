import os
from urllib import response
from dotenv import load_dotenv
from numpy import isin
import openai
import streamlit as st
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage

from data_source.langchain.lang_chain_chat_model_factory import LangchainChatModelFactory


def main():
    # .envã‚’èª­ã¿å–ã‚‹
    load_dotenv()

    st.set_page_config(page_title="Stream-AI-Chat", page_icon="ğŸ¤–")
    st.header("Stream-AI-Chat")

    llm = LangchainChatModelFactory.create_instance()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = [SystemMessage(content="")]

    # ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("Input Your Message..."):
        st.session_state.messages.append(HumanMessage(content=user_input))  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
        try:
            with st.spinner("Generating ChatGPT answers..."):
                response = llm(st.session_state.messages)  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
            st.session_state.messages.append(AIMessage(content=response.content))  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚

        except Exception as e:
            err_content_message = "æ„Ÿè¦šãŒçŸ­ã™ãã¾ã™ã€‚ä¸€å®šæ™‚é–“çµŒéå¾Œã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            st.session_state.messages.append(SystemMessage(content=err_content_message))
            pass

    messages = st.session_state.get("messages", [])
    if len(messages) > 1:
        for message in messages:
            if isinstance(message, AIMessage):
                with st.chat_message("Assistant"):
                    st.markdown(message.content)
            elif isinstance(message, HumanMessage):
                with st.chat_message("User"):
                    st.markdown(message.content)
            else:
                with st.chat_message("System"):
                    st.markdown(message.content)


if __name__ == "__main__":
    main()
