from typing import Any, List, Union
from urllib import response
from xmlrpc.client import boolean
from dotenv import load_dotenv
from numpy import isin
import openai
import streamlit as st
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage

from data_source.langchain.lang_chain_chat_model_factory import LangchainChatModelFactory
from data_source.openai_data_source import MODELS, Role


def create_converstations(
    messages: List[Union[HumanMessage, AIMessage, SystemMessage]], is_error: boolean
) -> None:
    for message in messages:
        if message.type == "ai":
            with st.chat_message(Role.ASSISTANT.value):
                st.markdown(message.content)
        elif message.type == "human":
            with st.chat_message(Role.UESR.value):
                st.markdown(message.content)
        else:
            if is_error:
                with st.chat_message(Role.SYSTEM.value):
                    st.markdown(message.content)


def generate_ai_messages(
    history_messages: List[Union[SystemMessage, Any]], llm: AzureChatOpenAI
) -> bool:
    try:
        with st.spinner("Generating ChatGPT answers..."):
            response = llm(history_messages)  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
        st.session_state.messages.append(AIMessage(content=response.content))  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚

    except openai.error.RateLimitError as e:  # type: ignore
        err_content_message = "æ„Ÿè¦šãŒçŸ­ã™ãã¾ã™ã€‚ä¸€å®šæ™‚é–“çµŒéå¾Œã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
        st.session_state.messages.append(SystemMessage(content=err_content_message))
        return True

    except Exception as e:
        print(e)
        err_content_message = "æƒ³å®šå¤–ã®ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚ç®¡ç†è€…ã«å•ã„åˆã‚ã›ã¦ãã ã•ã„ã€‚"
        st.session_state.messages.append(SystemMessage(content=err_content_message))
        return True

    return False


def main():
    # .envã‚’èª­ã¿å–ã‚‹
    load_dotenv()
    # ã‚¨ãƒ©ãƒ¼åˆ¤æ–­ãƒ•ãƒ©ã‚°åˆæœŸåŒ–
    is_error = False

    # ãƒšãƒ¼ã‚¸ã®åŸºæœ¬æ§‹æˆ

    ## ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ˜ãƒƒãƒ€ã®è¨­å®š
    st.set_page_config(page_title="Stream-AI-Chat", page_icon="ğŸ¤–")
    st.header("Stream-AI-Chat")

    ## ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
    st.sidebar.title("Options")
    model: Union[str, Any] = st.sidebar.radio("Choose a model: ", (MODELS.keys()))  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
    clear_button = st.sidebar.button("Clear Conversation", key="clear")  # ä¼šè©±å±¥æ­´å‰Šé™¤ãƒœã‚¿ãƒ³

    ## ã‚³ã‚¹ãƒˆè¡¨ç¤º
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown("**Total Cost**")
    for i in range(3):
        st.sidebar.markdown(f"- ${i+0.01}")

    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®è¿½åŠ (min=0, max=2, default=0.0, stride=0.1)
    temperature = st.sidebar.slider("Temperature: ", min_value=0.0, max_value=2.0, value=0.0, step=0.1)

    # AzureOpenAIã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    llm = LangchainChatModelFactory.create_instance(temperature, model)

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = [SystemMessage(content="")]

    # ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("Input Your Message..."):
        st.session_state.messages.append(HumanMessage(content=user_input))  # type: ignore //pylanceèª¤æ¤œçŸ¥ã®ãŸã‚
        # ä¼šè©±å±¥æ­´ã‚’ã‚‚ã¨ã«å›ç­”ç”Ÿæˆé–‹å§‹
        is_error = generate_ai_messages(st.session_state.messages, llm)

    messages = st.session_state.get("messages", [])
    if len(messages) > 1:
        # ä¼šè©±ã®æç”»
        create_converstations(messages, is_error)


if __name__ == "__main__":
    main()
